{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b9d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Ensemble Model Evaluation ---\n",
      "Error: The TinyBERT model directory '../models/tinybert_model' was not found.\n",
      "Please ensure your TinyBERT model is saved in this folder path.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# --- File Paths and Constants ---\n",
    "# Meta-Model and Vectorizer from the ensemble tuning\n",
    "META_MODEL_PATH = '../models/ensemble_meta_model.pkl'\n",
    "VECTORIZER_PATH = '../models/vectorizer_advanced_tuned.pkl'\n",
    "\n",
    "# Base models (needed for their predictions)\n",
    "GB_MODEL_PATH = '../models/gb_model_advanced_tuned.pkl'\n",
    "# The path to your local TinyBERT model folder\n",
    "TINYBERT_MODEL_PATH = '../models/tinybert_finetuned'\n",
    "\n",
    "# Dataset to be tested\n",
    "TEST_DATA_PATH = '../data/test_labeled_dataset_sampled.csv' # Using the sampled data for faster testing\n",
    "\n",
    "def test_ensemble_model():\n",
    "    \"\"\"\n",
    "    Loads the full ensemble pipeline, makes predictions on the pseudo-labeled\n",
    "    test data, and prints the performance report.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Ensemble Model Evaluation ---\")\n",
    "\n",
    "    # --- 1. Load the Necessary Components ---\n",
    "    if not os.path.exists(META_MODEL_PATH):\n",
    "        print(f\"Error: The meta-model file '{META_MODEL_PATH}' was not found.\")\n",
    "        return\n",
    "    if not os.path.exists(VECTORIZER_PATH):\n",
    "        print(f\"Error: The vectorizer file '{VECTORIZER_PATH}' was not found.\")\n",
    "        return\n",
    "    if not os.path.exists(GB_MODEL_PATH):\n",
    "        print(f\"Error: The Gradient Boosting model '{GB_MODEL_PATH}' was not found.\")\n",
    "        return\n",
    "    if not os.path.exists(TEST_DATA_PATH):\n",
    "        print(f\"Error: The test data file '{TEST_DATA_PATH}' was not found.\")\n",
    "        return\n",
    "    if not os.path.isdir(TINYBERT_MODEL_PATH):\n",
    "        print(f\"Error: The TinyBERT model directory '{TINYBERT_MODEL_PATH}' was not found.\")\n",
    "        print(\"Please ensure your TinyBERT model is saved in this folder path.\")\n",
    "        return\n",
    "\n",
    "    print(\"Loading all models and data...\")\n",
    "    meta_model = joblib.load(META_MODEL_PATH)\n",
    "    vectorizer = joblib.load(VECTORIZER_PATH)\n",
    "    gb_model = joblib.load(GB_MODEL_PATH)\n",
    "    \n",
    "    # TinyBERT model and tokenizer from the local directory\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TINYBERT_MODEL_PATH)\n",
    "    tinybert_model = AutoModelForSequenceClassification.from_pretrained(TINYBERT_MODEL_PATH)\n",
    "    tinybert_model.eval()\n",
    "\n",
    "    test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "    print(f\"Loaded {len(test_df)} reviews for testing.\")\n",
    "\n",
    "    # --- 2. Prepare the Data for the Ensemble Pipeline ---\n",
    "    X_test_text = test_df['text']\n",
    "    y_true = test_df['violation_type']\n",
    "\n",
    "    # --- 3. Get Probability Predictions from the Base Models ---\n",
    "    print(\"Generating predictions from base models...\")\n",
    "\n",
    "    # Gradient Boosting Model\n",
    "    X_test_tfidf = vectorizer.transform(X_test_text)\n",
    "    gb_probs = gb_model.predict_proba(X_test_tfidf)\n",
    "\n",
    "    # TinyBERT Model\n",
    "    tinybert_probs = []\n",
    "    for text in X_test_text:\n",
    "        # Tokenize the text and get model outputs\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = tinybert_model(**inputs)\n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1).numpy()\n",
    "        tinybert_probs.append(probabilities[0])\n",
    "\n",
    "    tinybert_probs = pd.DataFrame(tinybert_probs)\n",
    "\n",
    "    # --- 4. Combine Probabilities and Make Final Prediction ---\n",
    "    # The meta-model was trained on the concatenated probabilities\n",
    "    # The columns must be in the same order as during training\n",
    "    X_meta_test = pd.concat([pd.DataFrame(gb_probs), tinybert_probs], axis=1)\n",
    "\n",
    "    print(\"Making final predictions with the RandomForest meta-model...\")\n",
    "    y_pred = meta_model.predict(X_meta_test)\n",
    "\n",
    "    # --- 5. Evaluate and Report Results ---\n",
    "    print(\"\\n--- Evaluation Report ---\")\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Overall Ensemble Accuracy on New Data: {accuracy:.4f}\\n\")\n",
    "\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(\"Full Classification Report:\\n\")\n",
    "    print(report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_ensemble_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
